{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute number of valid time points\n",
    "\n",
    "Zizhuang Miao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem of continuous ratings is that participants most of the time could not provide valid ratings around the start of each trial; using data from a very small number of participants could lead to biased or wrong estimations of the group judgments. For that, I set the time points with more than 50% of missing data as invalid and mark them by a new indicator variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "dataDir = 'C:\\\\'\n",
    "threshold = 0.5    # change as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### social interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "for n in range(1,9):\n",
    "    oriData = pd.read_csv(join(dataDir, 'combined_social_consensus', f'narrative{n}_mean.csv'))\n",
    "    valid_threshold = []\n",
    "    for s in range(1,10):\n",
    "        trialData = oriData.loc[oriData.situation==s]\n",
    "        valid_threshold.append(round(trialData.iloc[0, 3] * threshold))\n",
    "    for i in range(len(oriData)):\n",
    "        oriData.loc[i, 'included'] = 0 if oriData.loc[i, 'validPar_time'] < valid_threshold[oriData.loc[i, 'situation']-1] else 1\n",
    "    oriData.to_csv(join(dataDir, 'combined_social_consensus', f'narrative{n}_mean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median\n",
    "for n in range(1,9):\n",
    "    oriData = pd.read_csv(join(dataDir, 'combined_social_consensus', f'narrative{n}_median.csv'))\n",
    "    valid_threshold = []\n",
    "    for s in range(1,10):\n",
    "        trialData = oriData.loc[oriData.situation==s]\n",
    "        valid_threshold.append(round(trialData.iloc[0, 3] * threshold))\n",
    "    for i in range(len(oriData)):\n",
    "        oriData.loc[i, 'included'] = 0 if oriData.loc[i, 'validPar_time'] < valid_threshold[oriData.loc[i, 'situation']-1] else 1\n",
    "    oriData.to_csv(join(dataDir, 'combined_social_consensus', f'narrative{n}_median.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### theory of mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "for n in range(1,9):\n",
    "    oriData = pd.read_csv(join(dataDir, 'combined_tom_consensus', f'narrative{n}_mean.csv'))\n",
    "    valid_threshold = []\n",
    "    for s in range(1,10):\n",
    "        trialData = oriData.loc[oriData.situation==s]\n",
    "        valid_threshold.append(round(trialData.iloc[0, 3] * threshold))\n",
    "    for i in range(len(oriData)):\n",
    "        oriData.loc[i, 'included'] = 0 if oriData.loc[i, 'validPar_time'] < valid_threshold[oriData.loc[i, 'situation']-1] else 1\n",
    "    oriData.to_csv(join(dataDir, 'combined_tom_consensus', f'narrative{n}_mean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# median\n",
    "for n in range(1,9):\n",
    "    oriData = pd.read_csv(join(dataDir, 'combined_tom_consensus', f'narrative{n}_median.csv'))\n",
    "    valid_threshold = []\n",
    "    for s in range(1,10):\n",
    "        trialData = oriData.loc[oriData.situation==s]\n",
    "        valid_threshold.append(round(trialData.iloc[0, 3] * threshold))\n",
    "    for i in range(len(oriData)):\n",
    "        oriData.loc[i, 'included'] = 0 if oriData.loc[i, 'validPar_time'] < valid_threshold[oriData.loc[i, 'situation']-1] else 1\n",
    "    oriData.to_csv(join(dataDir, 'combined_tom_consensus', f'narrative{n}_median.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
