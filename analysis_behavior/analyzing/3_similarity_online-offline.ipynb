{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate online ratings with offline annotations\n",
    "\n",
    "Zizhuang Miao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to calculate the correlations between online ratings and offline annotations of social interactions, and online ratings of ToM and offline ratings of ToM demands. Significance of the correlations will be tested using non-parametric methods (phase randomization) because of the autocorrelation of time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from nltools.stats import phase_randomize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   run         r       p\n",
      "0    1  0.481458  0.0008\n",
      "1    2  0.489046  0.0006\n",
      "2    3   0.63388     0.0\n",
      "3    4  0.587763     0.0\n",
      "4  all  0.578997     0.0\n"
     ]
    }
   ],
   "source": [
    "dataDir = 'C:\\\\'\n",
    "outputDir = 'C:\\\\'\n",
    "\n",
    "runDict = {1: [7, 8], 2: [5, 6], 3: [3, 4], 4: [1, 2]}\n",
    "nBoot = 10000\n",
    "\n",
    "allData = pd.DataFrame()\n",
    "\n",
    "corr_by_run = pd.DataFrame(columns=['run', 'r', 'p'])\n",
    "\n",
    "for run in runDict:\n",
    "    runData = pd.DataFrame()\n",
    "    corr_by_run.loc[run-1, 'run'] = run\n",
    "\n",
    "    # get the data for the run\n",
    "    for n in runDict[run]:\n",
    "        data = pd.read_csv(join(dataDir, f'narrative{n}_median.csv'))\n",
    "        data['narrative'] = n\n",
    "        if n%2 == 0:\n",
    "            data['time'] += runData['time'].max() + 0.23\n",
    "        runData = pd.concat([runData, data], axis=0)\n",
    "        runData = runData.reset_index(drop=True)\n",
    "\n",
    "    # estimate a null distribution the correlation between labels and medians by phase randomization\n",
    "    nullDist = np.zeros(nBoot)\n",
    "    corrData = runData[['labels', 'median']].dropna()\n",
    "    for i in range(nBoot):\n",
    "        nullDist[i] = np.corrcoef(phase_randomize(corrData['median']), corrData['labels'])[0, 1]\n",
    "    \n",
    "    pd.DataFrame({'correlation': nullDist}).to_csv(join(outputDir, 'nullDist', f'phasRandom_social_conti_v_cons_median_run{run}.csv'), index=False)\n",
    "\n",
    "    # calculate the correlation between labels and medians\n",
    "    r = np.corrcoef(corrData['median'], corrData['labels'])[0, 1]\n",
    "    p = np.sum(nullDist > r) * 2 / nBoot\n",
    "    corr_by_run.loc[run-1, 'r'] = r\n",
    "    corr_by_run.loc[run-1, 'p'] = p\n",
    "\n",
    "    allData = pd.concat([allData, runData], axis=0)\n",
    "\n",
    "# for all data across runs\n",
    "allData = allData.reset_index(drop=True)\n",
    "nullDist = np.zeros(nBoot)\n",
    "corrData = allData[['labels', 'median']].dropna()\n",
    "for i in range(nBoot):\n",
    "    nullDist[i] = np.corrcoef(phase_randomize(corrData['median']), corrData['labels'])[0, 1]\n",
    "pd.DataFrame({'correlation': nullDist}).to_csv(join(outputDir, 'nullDist', f'phasRandom_social_conti_v_cons_median_all.csv'), index=False)\n",
    "\n",
    "r = np.corrcoef(corrData['median'], corrData['labels'])[0, 1]\n",
    "p = np.sum(nullDist > r) * 2 / nBoot\n",
    "corr_by_run.loc[4, 'run'] = 'all'\n",
    "corr_by_run.loc[4, 'r'] = r\n",
    "corr_by_run.loc[4, 'p'] = p\n",
    "\n",
    "print(corr_by_run)\n",
    "corr_by_run.to_csv(join(outputDir, 'corr_social_conti_v_cons_median.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  modality         r       p\n",
      "0    audio  0.191432  0.0462\n",
      "1     text  0.140896  0.1092\n",
      "2      all  0.152662  0.0214\n"
     ]
    }
   ],
   "source": [
    "dataDir = 'C:\\\\'\n",
    "outputDir = 'C:\\\\'\n",
    "\n",
    "modalityDict = {'audio': [5, 6, 7, 8], 'text': [1, 2, 3, 4]}\n",
    "nBoot = 10000\n",
    "\n",
    "allData = pd.DataFrame()\n",
    "\n",
    "corr_by_run = pd.DataFrame(columns=['modality', 'r', 'p'])\n",
    "\n",
    "for i, mod in enumerate(modalityDict):\n",
    "    runData = pd.DataFrame()\n",
    "    corr_by_run.loc[i, 'modality'] = mod\n",
    "\n",
    "    # get the data for the run\n",
    "    for n in modalityDict[mod]:\n",
    "        data = pd.read_csv(join(dataDir, f'narrative{n}_median.csv'))\n",
    "        data['narrative'] = n\n",
    "        if n%4 != 1:\n",
    "            data['time'] += runData['time'].max() + 0.23\n",
    "        runData = pd.concat([runData, data], axis=0)\n",
    "        runData = runData.reset_index(drop=True)\n",
    "\n",
    "    # estimate a null distribution the correlation between labels and medians by phase randomization\n",
    "    nullDist = np.zeros(nBoot)\n",
    "    corrData = runData[['labels', 'median']].dropna()\n",
    "    for j in range(nBoot):\n",
    "        nullDist[j] = np.corrcoef(phase_randomize(corrData['median']), corrData['labels'])[0, 1]\n",
    "    \n",
    "    pd.DataFrame({'correlation': nullDist}).to_csv(join(outputDir, 'nullDist', f'phasRandom_tom_conti_v_cons_median_{mod}.csv'), index=False)\n",
    "\n",
    "    # calculate the correlation between labels and medians\n",
    "    r = np.corrcoef(corrData['median'], corrData['labels'])[0, 1]\n",
    "    p = np.sum(nullDist > r) * 2 / nBoot\n",
    "    corr_by_run.loc[i, 'r'] = r\n",
    "    corr_by_run.loc[i, 'p'] = p\n",
    "\n",
    "    allData = pd.concat([allData, runData], axis=0)\n",
    "\n",
    "# for all data across runs\n",
    "allData = allData.reset_index(drop=True)\n",
    "nullDist = np.zeros(nBoot)\n",
    "corrData = allData[['labels', 'median']].dropna()\n",
    "for j in range(nBoot):\n",
    "    nullDist[j] = np.corrcoef(phase_randomize(corrData['median']), corrData['labels'])[0, 1]\n",
    "pd.DataFrame({'correlation': nullDist}).to_csv(join(outputDir, 'nullDist', f'phasRandom_tom_conti_v_cons_median_all.csv'), index=False)\n",
    "\n",
    "r = np.corrcoef(corrData['median'], corrData['labels'])[0, 1]\n",
    "p = np.sum(nullDist > r) * 2 / nBoot\n",
    "corr_by_run.loc[2, 'modality'] = 'all'\n",
    "corr_by_run.loc[2, 'r'] = r\n",
    "corr_by_run.loc[2, 'p'] = p\n",
    "\n",
    "print(corr_by_run)\n",
    "corr_by_run.to_csv(join(outputDir, 'corr_tom_conti_v_cons_median_modality.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
