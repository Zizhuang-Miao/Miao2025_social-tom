{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data evaluation for continuous ratings\n",
    "\n",
    "Zizhuang Miao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to correlate the means/medians of online participants' ratings with experimenters' annotations to see how similar they are. Along the way of analysis, this script also generates and saves .csv files that include both the mean/medians of online participants' ratings and the (resampled) experimenters' annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.595862\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.340888\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412228\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.504397\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608431\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.439736\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.291491\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.554428\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495364\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "dataDir = 'C:\\\\'\n",
    "parDataDir = join(dataDir, 'continuous_social_1a2a3a4a_long')\n",
    "manualDataDir = join(dataDir, 'manualAnnotations_social_consensus')\n",
    "outputDir = 'C:\\\\'\n",
    "\n",
    "# this is a list of subjects whose ratings are not like the average of other participants (correlation < 0.3 across all narratives)\n",
    "# we will exclude them from generating group-level summary statistics\n",
    "badSub = pd.read_csv('C:\\\\')['ID']\n",
    "\n",
    "corr_narrative = []\n",
    "regress_pRsquare_narrative = []\n",
    "regress_z_narrative = []\n",
    "t_narratvie = []\n",
    "p_t_narrative = []\n",
    "\n",
    "allData = pd.DataFrame()\n",
    "\n",
    "for n in range(1,9):\n",
    "    parData = pd.DataFrame()\n",
    "    manualData = pd.DataFrame()\n",
    "    lastTimepoint, lastTimepoint2 = [], []    # the last time points in each situation\n",
    "\n",
    "    for s in range(1,10):\n",
    "        # participants' ratings\n",
    "        parDat = pd.read_csv(join(parDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            parDat['time'] += 0.23\n",
    "            parDat['time'] += lastTimepoint[-1]\n",
    "        lastTimepoint.append(parDat.loc[len(parDat)-1, 'time'])\n",
    "        \n",
    "        parDat = parDat[~parDat['ID'].isin(badSub)]    # excluding subjects that are not like the group\n",
    "        \n",
    "        parData = pd.concat([parData, parDat], ignore_index=True)\n",
    "        parData = parData.drop(columns='index') if s!=1 else parData\n",
    "        parData = parData.reset_index()\n",
    "\n",
    "        # manual ratings\n",
    "        manualDat = pd.read_csv(join(manualDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            manualDat['time'] += 0.23\n",
    "            manualDat['time'] += lastTimepoint2[-1]\n",
    "        lastTimepoint2.append(manualDat.loc[len(manualDat)-1, 'time'])\n",
    "        manualDat['situation'] = s\n",
    "        manualDat['validPar_trial'] = len(np.unique(parDat['ID']))     # the number of participants who have valid data in this trial\n",
    "        \n",
    "        nvalid_time = parDat.groupby('time').count()    # the number of participants who have valid data at each time point\n",
    "        nvalid_time = nvalid_time.reset_index()\n",
    "        manualDat['validPar_time'] = nvalid_time['rating']\n",
    "        \n",
    "        manualData = pd.concat([manualData, manualDat], ignore_index=True)\n",
    "        manualData = manualData.drop(columns='index') if s!= 1 else manualData\n",
    "        manualData = manualData.reset_index()\n",
    "\n",
    "    manualData = manualData.drop(columns='index')\n",
    "    manualData.columns = ['time', 'labels', 'situation', 'validPar_trial', 'validPar_time']\n",
    "    manualData = manualData[['situation', 'time', 'labels', 'validPar_trial', 'validPar_time']]\n",
    "    \n",
    "    parData_mean = parData.groupby('time')['rating'].mean()\n",
    "    parData_mean = parData_mean.reset_index()\n",
    "    parData_mean = parData_mean.drop(columns='time')\n",
    "    parData_mean.columns = ['mean']\n",
    "    parData_std = parData.groupby('time')['rating'].std()\n",
    "    parData_std = parData_std.reset_index()\n",
    "    parData_std = parData_std.drop(columns='time')\n",
    "    parData_std.columns = ['std']\n",
    "    \n",
    "    combinedData = pd.concat([manualData, parData_mean, parData_std], axis=1)\n",
    "    combinedData.to_csv(join(dataDir, 'combined_social_consensus', f'narrative{n}_mean.csv'), index=False)\n",
    "    allData = pd.concat([allData, combinedData], ignore_index=True)\n",
    "\n",
    "    # calculate metrics\n",
    "    # correlation\n",
    "    corr_narrative.append(combinedData['labels'].corr(combinedData['mean']))\n",
    "    # logistic regression\n",
    "    binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in combinedData['labels']]})\n",
    "    X = combinedData['mean']\n",
    "    binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "    X = sm.add_constant(X)\n",
    "    X = X.dropna()\n",
    "    logit_model = sm.Logit(binLabels, X)\n",
    "    result = logit_model.fit()\n",
    "    regress_pRsquare_narrative.append(result.prsquared)\n",
    "    regress_z_narrative.append(result.tvalues[1])\n",
    "    # t test\n",
    "    t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "    t_narratvie.append(t_stat)\n",
    "    p_t_narrative.append(p_val)\n",
    "\n",
    "# calculate metrics for all narratives concatenated\n",
    "# correlation\n",
    "corr_narrative.append(allData['labels'].corr(allData['mean']))\n",
    "# logistic regression\n",
    "binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in allData['labels']]})\n",
    "X = allData['mean']\n",
    "binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "X = sm.add_constant(X)\n",
    "X = X.dropna()\n",
    "logit_model = sm.Logit(binLabels, X)\n",
    "result = logit_model.fit()\n",
    "regress_pRsquare_narrative.append(result.prsquared)\n",
    "regress_z_narrative.append(result.tvalues[1])\n",
    "# t test\n",
    "t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "t_narratvie.append(t_stat)\n",
    "p_t_narrative.append(p_val)\n",
    "\n",
    "\n",
    "outputDf_narrative = pd.DataFrame({'narrative': list(range(1,9)) + ['All'], \n",
    "                                   'pearson_r': corr_narrative, 't': t_narratvie, 'p_ttest': p_t_narrative,\n",
    "                                   'z_logistic': regress_z_narrative, 'pseudo_r': regress_pRsquare_narrative})\n",
    "outputDf_narrative = outputDf_narrative.round(3)\n",
    "outputDf_narrative.to_csv(join(outputDir, 'similarity_social_consensus_mean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.593052\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.349076\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426978\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503582\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.611826\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.446155\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296978\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.559985\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.498439\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "dataDir = 'C:\\\\'\n",
    "parDataDir = join(dataDir, 'continuous_social_1a2a3a4a_long')\n",
    "manualDataDir = join(dataDir, 'manualAnnotations_social_consensus')\n",
    "outputDir = 'C:\\\\'\n",
    "\n",
    "badSub = pd.read_csv('C:\\\\')['ID']\n",
    "\n",
    "corr_narrative = []\n",
    "regress_pRsquare_narrative = []\n",
    "regress_z_narrative = []\n",
    "t_narratvie = []\n",
    "p_t_narrative = []\n",
    "\n",
    "allData = pd.DataFrame()\n",
    "\n",
    "for n in range(1,9):\n",
    "    parData = pd.DataFrame()\n",
    "    manualData = pd.DataFrame()\n",
    "    lastTimepoint, lastTimepoint2 = [], []    # the last time points in each situation\n",
    "\n",
    "    for s in range(1,10):\n",
    "        # participants' ratings\n",
    "        parDat = pd.read_csv(join(parDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            parDat['time'] += 0.23\n",
    "            parDat['time'] += lastTimepoint[-1]\n",
    "        lastTimepoint.append(parDat.loc[len(parDat)-1, 'time'])\n",
    "        parDat = parDat[~parDat['ID'].isin(badSub)]    # excluding subjects that are not like the group\n",
    "        parData = pd.concat([parData, parDat])\n",
    "        parData = parData.drop(columns='index') if s!=1 else parData\n",
    "        parData = parData.reset_index()\n",
    "\n",
    "        # manual ratings\n",
    "        manualDat = pd.read_csv(join(manualDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            manualDat['time'] += 0.23\n",
    "            manualDat['time'] += lastTimepoint2[-1]\n",
    "        lastTimepoint2.append(manualDat.loc[len(manualDat)-1, 'time'])\n",
    "        manualDat['situation'] = s\n",
    "        manualDat['validPar_trial'] = len(np.unique(parDat['ID']))     # the number of participants who have valid data in this trial\n",
    "        nvalid_time = parDat.groupby('time').count()    # the number of participants who have valid data at each time point\n",
    "        nvalid_time = nvalid_time.reset_index()\n",
    "        manualDat['validPar_time'] = nvalid_time['rating']\n",
    "        manualData = pd.concat([manualData, manualDat])\n",
    "        manualData = manualData.drop(columns='index') if s!= 1 else manualData\n",
    "        manualData = manualData.reset_index()\n",
    "\n",
    "    manualData = manualData.drop(columns='index')\n",
    "    manualData.columns = ['time', 'labels', 'situation', 'validPar_trial', 'validPar_time']\n",
    "    manualData = manualData[['situation', 'time', 'labels', 'validPar_trial', 'validPar_time']]\n",
    "    parData_median = parData.groupby('time')['rating'].median()\n",
    "    parData_median = parData_median.reset_index()\n",
    "    parData_median = parData_median.drop(columns='time')\n",
    "    parData_median.columns = ['median']\n",
    "    parData_mad = parData.dropna().groupby('time')['rating'].apply(median_abs_deviation)\n",
    "    parData_mad = parData_mad.reset_index()\n",
    "    parData_mad = parData_mad.drop(columns='time')\n",
    "    parData_mad.columns = ['mad']\n",
    "    combinedData = pd.concat([manualData, parData_median, parData_mad], axis=1)\n",
    "    combinedData.to_csv(join(dataDir, 'combined_social_consensus', f'narrative{n}_median.csv'), index=False)\n",
    "    allData = pd.concat([allData, combinedData], ignore_index=True)\n",
    "\n",
    "    # calculate metrics\n",
    "    # correlation\n",
    "    corr_narrative.append(combinedData['labels'].corr(combinedData['median']))\n",
    "    # logistic regression\n",
    "    binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in combinedData['labels']]})\n",
    "    X = combinedData['median']\n",
    "    binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "    X = sm.add_constant(X)\n",
    "    X = X.dropna()\n",
    "    logit_model = sm.Logit(binLabels, X)\n",
    "    result = logit_model.fit()\n",
    "    regress_pRsquare_narrative.append(result.prsquared)\n",
    "    regress_z_narrative.append(result.tvalues[1])\n",
    "    # t test\n",
    "    t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "    t_narratvie.append(t_stat)\n",
    "    p_t_narrative.append(p_val)\n",
    "\n",
    "# calculate metrics for all narratives concatenated\n",
    "# correlation\n",
    "corr_narrative.append(allData['labels'].corr(allData['median']))\n",
    "# logistic regression\n",
    "binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in allData['labels']]})\n",
    "X = allData['median']\n",
    "binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "X = sm.add_constant(X)\n",
    "X = X.dropna()\n",
    "logit_model = sm.Logit(binLabels, X)\n",
    "result = logit_model.fit()\n",
    "regress_pRsquare_narrative.append(result.prsquared)\n",
    "regress_z_narrative.append(result.tvalues[1])\n",
    "# t test\n",
    "t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "t_narratvie.append(t_stat)\n",
    "p_t_narrative.append(p_val)\n",
    "\n",
    "\n",
    "outputDf_narrative = pd.DataFrame({'narrative': list(range(1,9)) + ['All'], \n",
    "                                   'pearson_r': corr_narrative, 't': t_narratvie, 'p_ttest': p_t_narrative,\n",
    "                                   'z_logistic': regress_z_narrative, 'pseudo_r': regress_pRsquare_narrative})\n",
    "outputDf_narrative = outputDf_narrative.round(3)\n",
    "outputDf_narrative.to_csv(join(outputDir, 'similarity_social_consensus_median.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory of mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.635329\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689536\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648266\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.655832\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648446\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628600\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651065\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669272\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.667591\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "dataDir = 'C:\\\\'\n",
    "parDataDir = join(dataDir, 'continuous_tom_1a2a3a4a_long')\n",
    "manualDataDir = join(dataDir, 'manualAnnotations_tom_zizhuang')\n",
    "outputDir = 'C:\\\\'\n",
    "\n",
    "# this is a list of subjects whose ratings are not like the average of other participants (correlation < 0.2 across all narratives)\n",
    "# we will exclude them from generating group-level summary statistics\n",
    "badSub = pd.read_csv('C:\\\\')['ID']\n",
    "\n",
    "corr_narrative = []\n",
    "regress_pRsquare_narrative = []\n",
    "regress_z_narrative = []\n",
    "t_narratvie = []\n",
    "p_t_narrative = []\n",
    "\n",
    "allData = pd.DataFrame()\n",
    "\n",
    "for n in range(1,9):\n",
    "    parData = pd.DataFrame()\n",
    "    manualData = pd.DataFrame()\n",
    "    lastTimepoint, lastTimepoint2 = [], []    # the last time points in each situation\n",
    "\n",
    "    for s in range(1,10):\n",
    "        # participants' ratings\n",
    "        parDat = pd.read_csv(join(parDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            parDat['time'] += 0.23\n",
    "            parDat['time'] += lastTimepoint[-1]\n",
    "        lastTimepoint.append(parDat.loc[len(parDat)-1, 'time'])\n",
    "        \n",
    "        parDat = parDat[~parDat['ID'].isin(badSub)]    # excluding subjects that are not like the group\n",
    "        \n",
    "        parData = pd.concat([parData, parDat], ignore_index=True)\n",
    "        parData = parData.drop(columns='index') if s!=1 else parData\n",
    "        parData = parData.reset_index()\n",
    "\n",
    "        # manual ratings\n",
    "        manualDat = pd.read_csv(join(manualDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            manualDat['time'] += 0.23\n",
    "            manualDat['time'] += lastTimepoint2[-1]\n",
    "        lastTimepoint2.append(manualDat.loc[len(manualDat)-1, 'time'])\n",
    "        manualDat['situation'] = s\n",
    "        manualDat['validPar_trial'] = len(np.unique(parDat['ID']))     # the number of participants who have valid data in this trial\n",
    "        \n",
    "        nvalid_time = parDat.groupby('time').count()    # the number of participants who have valid data at each time point\n",
    "        nvalid_time = nvalid_time.reset_index()\n",
    "        manualDat['validPar_time'] = nvalid_time['rating']\n",
    "        \n",
    "        manualData = pd.concat([manualData, manualDat], ignore_index=True)\n",
    "        manualData = manualData.drop(columns='index') if s!= 1 else manualData\n",
    "        manualData = manualData.reset_index()\n",
    "\n",
    "    manualData = manualData.drop(columns='index')\n",
    "    manualData.columns = ['time', 'labels', 'situation', 'validPar_trial', 'validPar_time']\n",
    "    manualData = manualData[['situation', 'time', 'labels', 'validPar_trial', 'validPar_time']]\n",
    "    \n",
    "    parData_mean = parData.groupby('time')['rating'].mean()\n",
    "    parData_mean = parData_mean.reset_index()\n",
    "    parData_mean = parData_mean.drop(columns='time')\n",
    "    parData_mean.columns = ['mean']\n",
    "    parData_std = parData.groupby('time')['rating'].std()\n",
    "    parData_std = parData_std.reset_index()\n",
    "    parData_std = parData_std.drop(columns='time')\n",
    "    parData_std.columns = ['std']\n",
    "    \n",
    "    combinedData = pd.concat([manualData, parData_mean, parData_std], axis=1)\n",
    "    combinedData.to_csv(join(dataDir, 'combined_tom_zizhuang', f'narrative{n}_mean.csv'), index=False)\n",
    "    allData = pd.concat([allData, combinedData], ignore_index=True)\n",
    "\n",
    "    # calculate metrics\n",
    "    # correlation\n",
    "    corr_narrative.append(combinedData['labels'].corr(combinedData['mean']))\n",
    "    # logistic regression\n",
    "    binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in combinedData['labels']]})\n",
    "    X = combinedData['mean']\n",
    "    binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "    X = sm.add_constant(X)\n",
    "    X = X.dropna()\n",
    "    logit_model = sm.Logit(binLabels, X)\n",
    "    result = logit_model.fit()\n",
    "    regress_pRsquare_narrative.append(result.prsquared)\n",
    "    regress_z_narrative.append(result.tvalues[1])\n",
    "    # t test\n",
    "    t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "    t_narratvie.append(t_stat)\n",
    "    p_t_narrative.append(p_val)\n",
    "\n",
    "# calculate metrics for all narratives concatenated\n",
    "# correlation\n",
    "corr_narrative.append(allData['labels'].corr(allData['mean']))\n",
    "# logistic regression\n",
    "binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in allData['labels']]})\n",
    "X = allData['mean']\n",
    "binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "X = sm.add_constant(X)\n",
    "X = X.dropna()\n",
    "logit_model = sm.Logit(binLabels, X)\n",
    "result = logit_model.fit()\n",
    "regress_pRsquare_narrative.append(result.prsquared)\n",
    "regress_z_narrative.append(result.tvalues[1])\n",
    "# t test\n",
    "t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "t_narratvie.append(t_stat)\n",
    "p_t_narrative.append(p_val)\n",
    "\n",
    "\n",
    "outputDf_narrative = pd.DataFrame({'narrative': list(range(1,9)) + ['All'], \n",
    "                                   'pearson_r': corr_narrative, 't': t_narratvie, 'p_ttest': p_t_narrative,\n",
    "                                   'z_logistic': regress_z_narrative, 'pseudo_r': regress_pRsquare_narrative})\n",
    "outputDf_narrative = outputDf_narrative.round(3)\n",
    "#outputDf_narrative.to_csv(join(outputDir, 'similarity_con_tom_1a2a3a4a5a.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.634454\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.688505\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.647223\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.655465\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656165\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.642057\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653317\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669391\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668375\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "dataDir = 'C:\\\\'\n",
    "parDataDir = join(dataDir, 'continuous_tom_1a2a3a4a_long')\n",
    "manualDataDir = join(dataDir, 'manualAnnotations_tom_zizhuang')\n",
    "outputDir = 'C:\\\\'\n",
    "\n",
    "badSub = pd.read_csv('C:\\\\')['ID']\n",
    "\n",
    "corr_narrative = []\n",
    "regress_pRsquare_narrative = []\n",
    "regress_z_narrative = []\n",
    "t_narratvie = []\n",
    "p_t_narrative = []\n",
    "\n",
    "allData = pd.DataFrame()\n",
    "\n",
    "for n in range(1,9):\n",
    "    parData = pd.DataFrame()\n",
    "    manualData = pd.DataFrame()\n",
    "    lastTimepoint, lastTimepoint2 = [], []    # the last time points in each situation\n",
    "\n",
    "    for s in range(1,10):\n",
    "        # participants' ratings\n",
    "        parDat = pd.read_csv(join(parDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            parDat['time'] += 0.23\n",
    "            parDat['time'] += lastTimepoint[-1]\n",
    "        lastTimepoint.append(parDat.loc[len(parDat)-1, 'time'])\n",
    "        parDat = parDat[~parDat['ID'].isin(badSub)]    # excluding subjects that are not like the group\n",
    "        parData = pd.concat([parData, parDat])\n",
    "        parData = parData.drop(columns='index') if s!=1 else parData\n",
    "        parData = parData.reset_index()\n",
    "\n",
    "        # manual ratings\n",
    "        manualDat = pd.read_csv(join(manualDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            manualDat['time'] += 0.23\n",
    "            manualDat['time'] += lastTimepoint2[-1]\n",
    "        lastTimepoint2.append(manualDat.loc[len(manualDat)-1, 'time'])\n",
    "        manualDat['situation'] = s\n",
    "        manualDat['validPar_trial'] = len(np.unique(parDat['ID']))     # the number of participants who have valid data in this trial\n",
    "        nvalid_time = parDat.groupby('time').count()    # the number of participants who have valid data at each time point\n",
    "        nvalid_time = nvalid_time.reset_index()\n",
    "        manualDat['validPar_time'] = nvalid_time['rating']\n",
    "        manualData = pd.concat([manualData, manualDat])\n",
    "        manualData = manualData.drop(columns='index') if s!= 1 else manualData\n",
    "        manualData = manualData.reset_index()\n",
    "\n",
    "    manualData = manualData.drop(columns='index')\n",
    "    manualData.columns = ['time', 'labels', 'situation', 'validPar_trial', 'validPar_time']\n",
    "    manualData = manualData[['situation', 'time', 'labels', 'validPar_trial', 'validPar_time']]\n",
    "    \n",
    "    parData_median = parData.groupby('time')['rating'].median()\n",
    "    parData_median = parData_median.reset_index()\n",
    "    parData_median = parData_median.drop(columns='time')\n",
    "    parData_median.columns = ['median']\n",
    "    parData_mad = parData.dropna().groupby('time')['rating'].apply(median_abs_deviation)\n",
    "    parData_mad = parData_mad.reset_index()\n",
    "    parData_mad = parData_mad.drop(columns='time')\n",
    "    parData_mad.columns = ['mad']\n",
    "    \n",
    "    combinedData = pd.concat([manualData, parData_median, parData_mad], axis=1)\n",
    "    combinedData.to_csv(join(dataDir, 'combined_tom_zizhuang', f'narrative{n}_median.csv'), index=False)\n",
    "    allData = pd.concat([allData, combinedData], ignore_index=True)\n",
    "\n",
    "    # calculate metrics\n",
    "    # correlation\n",
    "    corr_narrative.append(combinedData['labels'].corr(combinedData['median']))\n",
    "    # logistic regression\n",
    "    binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in combinedData['labels']]})\n",
    "    X = combinedData['median']\n",
    "    binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "    X = sm.add_constant(X)\n",
    "    X = X.dropna()\n",
    "    logit_model = sm.Logit(binLabels, X)\n",
    "    result = logit_model.fit()\n",
    "    regress_pRsquare_narrative.append(result.prsquared)\n",
    "    regress_z_narrative.append(result.tvalues[1])\n",
    "    # t test\n",
    "    t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "    t_narratvie.append(t_stat)\n",
    "    p_t_narrative.append(p_val)\n",
    "\n",
    "# calculate metrics for all narratives concatenated\n",
    "# correlation\n",
    "corr_narrative.append(allData['labels'].corr(allData['median']))\n",
    "# logistic regression\n",
    "binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in allData['labels']]})\n",
    "X = allData['median']\n",
    "binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "X = sm.add_constant(X)\n",
    "X = X.dropna()\n",
    "logit_model = sm.Logit(binLabels, X)\n",
    "result = logit_model.fit()\n",
    "regress_pRsquare_narrative.append(result.prsquared)\n",
    "regress_z_narrative.append(result.tvalues[1])\n",
    "# t test\n",
    "t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "t_narratvie.append(t_stat)\n",
    "p_t_narrative.append(p_val)\n",
    "\n",
    "\n",
    "outputDf_narrative = pd.DataFrame({'narrative': list(range(1,9)) + ['All'], \n",
    "                                   'pearson_r': corr_narrative, 't': t_narratvie, 'p_ttest': p_t_narrative,\n",
    "                                   'z_logistic': regress_z_narrative, 'pseudo_r': regress_pRsquare_narrative})\n",
    "outputDf_narrative = outputDf_narrative.round(3)\n",
    "outputDf_narrative.to_csv(join(outputDir, 'similarity_tom_conti_v_zizhuang_median.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Calculate similarity between ToM and ToM demands by consensus labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.662772\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683457\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.667131\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.685041\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.599663\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669779\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.666869\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668652\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.675817\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "dataDir = 'C:\\\\'\n",
    "parDataDir = join(dataDir, 'continuous_tom_1a2a3a4a_long')\n",
    "manualDataDir = join(dataDir, 'manualAnnotations_tom_demands_consensus')\n",
    "outputDir = 'C:\\\\'\n",
    "\n",
    "badSub = pd.read_csv('C:\\\\')['ID']\n",
    "\n",
    "corr_narrative = []\n",
    "regress_pRsquare_narrative = []\n",
    "regress_z_narrative = []\n",
    "t_narratvie = []\n",
    "p_t_narrative = []\n",
    "\n",
    "allData = pd.DataFrame()\n",
    "\n",
    "for n in range(1,9):\n",
    "    parData = pd.DataFrame()\n",
    "    manualData = pd.DataFrame()\n",
    "    lastTimepoint, lastTimepoint2 = [], []    # the last time points in each situation\n",
    "\n",
    "    for s in range(1,10):\n",
    "        # participants' ratings\n",
    "        parDat = pd.read_csv(join(parDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            parDat['time'] += 0.23\n",
    "            parDat['time'] += lastTimepoint[-1]\n",
    "        lastTimepoint.append(parDat.loc[len(parDat)-1, 'time'])\n",
    "        parDat = parDat[~parDat['ID'].isin(badSub)]    # excluding subjects that are not like the group\n",
    "        parData = pd.concat([parData, parDat])\n",
    "        parData = parData.drop(columns='index') if s!=1 else parData\n",
    "        parData = parData.reset_index()\n",
    "\n",
    "        # manual ratings\n",
    "        manualDat = pd.read_csv(join(manualDataDir, f\"narrative{n}situation{s}.csv\"))\n",
    "        if s != 1:\n",
    "            manualDat['time'] += 0.23\n",
    "            manualDat['time'] += lastTimepoint2[-1]\n",
    "        lastTimepoint2.append(manualDat.loc[len(manualDat)-1, 'time'])\n",
    "        manualDat['situation'] = s\n",
    "        manualDat['validPar_trial'] = len(np.unique(parDat['ID']))     # the number of participants who have valid data in this trial\n",
    "        nvalid_time = parDat.groupby('time').count()    # the number of participants who have valid data at each time point\n",
    "        nvalid_time = nvalid_time.reset_index()\n",
    "        manualDat['validPar_time'] = nvalid_time['rating']\n",
    "        manualData = pd.concat([manualData, manualDat])\n",
    "        manualData = manualData.drop(columns='index') if s!= 1 else manualData\n",
    "        manualData = manualData.reset_index()\n",
    "\n",
    "    manualData = manualData.drop(columns='index')\n",
    "    manualData.columns = ['time', 'labels', 'situation', 'validPar_trial', 'validPar_time']\n",
    "    manualData = manualData[['situation', 'time', 'labels', 'validPar_trial', 'validPar_time']]\n",
    "    \n",
    "    parData_median = parData.groupby('time')['rating'].median()\n",
    "    parData_median = parData_median.reset_index()\n",
    "    parData_median = parData_median.drop(columns='time')\n",
    "    parData_median.columns = ['median']\n",
    "    parData_mad = parData.dropna().groupby('time')['rating'].apply(median_abs_deviation)\n",
    "    parData_mad = parData_mad.reset_index()\n",
    "    parData_mad = parData_mad.drop(columns='time')\n",
    "    parData_mad.columns = ['mad']\n",
    "    \n",
    "    combinedData = pd.concat([manualData, parData_median, parData_mad], axis=1)\n",
    "    combinedData.to_csv(join(dataDir, 'combined_tom_consensus', f'narrative{n}_median.csv'), index=False)\n",
    "    allData = pd.concat([allData, combinedData], ignore_index=True)\n",
    "\n",
    "    # calculate metrics\n",
    "    # correlation\n",
    "    corr_narrative.append(combinedData['labels'].corr(combinedData['median']))\n",
    "    # logistic regression\n",
    "    binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in combinedData['labels']]})\n",
    "    X = combinedData['median']\n",
    "    binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "    X = sm.add_constant(X)\n",
    "    X = X.dropna()\n",
    "    logit_model = sm.Logit(binLabels, X)\n",
    "    result = logit_model.fit()\n",
    "    regress_pRsquare_narrative.append(result.prsquared)\n",
    "    regress_z_narrative.append(result.tvalues[1])\n",
    "    # t test\n",
    "    t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "    t_narratvie.append(t_stat)\n",
    "    p_t_narrative.append(p_val)\n",
    "\n",
    "# calculate metrics for all narratives concatenated\n",
    "# correlation\n",
    "corr_narrative.append(allData['labels'].corr(allData['median']))\n",
    "# logistic regression\n",
    "binLabels = pd.DataFrame({'labels': [1 if x > 50 else 0 for x in allData['labels']]})\n",
    "X = allData['median']\n",
    "binLabels = binLabels.loc[~X.isna(), 'labels']\n",
    "X = sm.add_constant(X)\n",
    "X = X.dropna()\n",
    "logit_model = sm.Logit(binLabels, X)\n",
    "result = logit_model.fit()\n",
    "regress_pRsquare_narrative.append(result.prsquared)\n",
    "regress_z_narrative.append(result.tvalues[1])\n",
    "# t test\n",
    "t_stat, p_val = ttest_ind(binLabels, X.iloc[:, 1])\n",
    "t_narratvie.append(t_stat)\n",
    "p_t_narrative.append(p_val)\n",
    "\n",
    "\n",
    "outputDf_narrative = pd.DataFrame({'narrative': list(range(1,9)) + ['All'], \n",
    "                                   'pearson_r': corr_narrative, 't': t_narratvie, 'p_ttest': p_t_narrative,\n",
    "                                   'z_logistic': regress_z_narrative, 'pseudo_r': regress_pRsquare_narrative})\n",
    "outputDf_narrative = outputDf_narrative.round(3)\n",
    "outputDf_narrative.to_csv(join(outputDir, 'similarity_tom_conti_v_cons_median.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
