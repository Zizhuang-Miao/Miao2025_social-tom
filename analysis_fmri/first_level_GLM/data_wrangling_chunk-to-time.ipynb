{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6eef72",
   "metadata": {},
   "source": [
    "## From chunk-level judgments to time-matched ratings\n",
    "\n",
    "Zizhuang Miao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89060660",
   "metadata": {},
   "source": [
    "This script is used to map chunk-level judgments (e.g., annotations on indoor and outdoor scenes for each sentence) to word-level annotations so that they are comparable with other features. The specific method for matching is nearest neighbor -- we find the word closest to each sample of continuous ratings (of social interactions, ToM, and multi-person presence), and then find the start and end word of each chunk in that time series. All words in between will bear the same annotations.\n",
    "\n",
    "This is how we got all features matched at the time points of online ratings.\n",
    "\n",
    "Below we provide example codes with indoor versus ourdoor annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff13748",
   "metadata": {},
   "source": [
    "### Indoor/Outdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37063a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"\"    # directory where the online ratings with word matched to each time point\n",
    "outputDir = \"\"\n",
    "\n",
    "ratings = pd.read_csv('')    # the chunk-level ratings file with 'Story' and 'indoor' columns, with each row being a sentence\n",
    "chunk_idx = 0    # index the chunk in the ratings file\n",
    "\n",
    "for n in range(1, 9):\n",
    "    df = pd.read_csv(os.path.join(dataDir, f\"narrative{n}.csv\"))\n",
    "    df['indoor'], df['outdoor'] = np.nan, np.nan\n",
    "\n",
    "    chunk_words = ratings.loc[chunk_idx, 'Story'].split()\n",
    "    chunk_words = [word.strip(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\").lower() for word in chunk_words]     # remove all punctuations for chunk_words\n",
    "    n_words = len(chunk_words)\n",
    "\n",
    "    first_idx, last_idx = 0, 0\n",
    "    \n",
    "    while not first_idx >= len(df):    # going through all the words in the df\n",
    "        df_idx = first_idx    # where in the df we are currently at\n",
    "        word_list = [(df_idx, df.loc[df_idx, 'word'].lower())]    # a list of new words and their index\n",
    "        while len(word_list) < n_words:\n",
    "            df_idx += 1\n",
    "            if df_idx == len(df):    # if we reach the end of the df, we break\n",
    "                break\n",
    "            if df.loc[df_idx, 'word'].lower() != df.loc[df_idx-1, 'word'].lower():\n",
    "                word_list.append((df_idx, df.loc[df_idx, 'word'].lower()))\n",
    "        \n",
    "        # now we have a list of words whose number match the chunk_words, or who are the final words in the df\n",
    "        # we check if some words in the chunk_words are not in the word_list\n",
    "        if word_list[-1][1].strip(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\") != chunk_words[-1]:\n",
    "            # some words are missing\n",
    "            # if the last word in the chunk_words is in the word_list, find it\n",
    "            if chunk_words[-1] in [w.strip(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\") for _, w in word_list]:\n",
    "                for i in range(len(word_list)-1, -1, -1):\n",
    "                    if word_list[i][1].strip(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\") == chunk_words[-1] and (not word_list[i][1] == word_list[i-1][1]):\n",
    "                        last_idx = word_list[i+1][0] - 1\n",
    "                        break\n",
    "            # if not, find the second last word in the chunk_words\n",
    "            elif chunk_words[-2] in [w.strip(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\") for _, w in word_list]:\n",
    "                for i in range(len(word_list)-1, -1, -1):\n",
    "                    if word_list[i][1].strip(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\") == chunk_words[-2] and (not word_list[i][1] == word_list[i-1][1]):\n",
    "                        last_idx = word_list[i+1][0] - 1\n",
    "                        break\n",
    "\n",
    "        else:\n",
    "            # we have a match\n",
    "            # find the end index of the chunk\n",
    "            if df_idx < len(df) - 1:\n",
    "                df_idx += 1\n",
    "                while df.loc[df_idx, 'word'].lower() == df.loc[df_idx-1, 'word'].lower():\n",
    "                    if df_idx < len(df) - 1:\n",
    "                        df_idx += 1\n",
    "                    else:\n",
    "                        break\n",
    "                last_idx = df_idx - 1 if df_idx < len(df) - 1 else df_idx  # the last index of the chunk, before the next new word\n",
    "            else:\n",
    "                last_idx = df_idx\n",
    "        \n",
    "        # now we have the first and last index of the chunk in the df, we can assign the ratings to the df\n",
    "        df.loc[first_idx:last_idx, 'indoor'] = ratings.loc[chunk_idx, 'indoor']\n",
    "        df.loc[first_idx:last_idx, 'outdoor'] = 1 - ratings.loc[chunk_idx, 'indoor']\n",
    "        chunk_idx += 1    # move to the next chunk\n",
    "        if chunk_idx >= len(ratings):\n",
    "            break    # we have reached the end of the ratings file\n",
    "        chunk_words = ratings.loc[chunk_idx, 'Story'].split()\n",
    "        chunk_words = [word.strip(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\").lower() for word in chunk_words]     # remove all punctuations for chunk_words\n",
    "        n_words = len(chunk_words)\n",
    "        first_idx = last_idx + 1    # move to the next chunk in the df\n",
    "    \n",
    "    # save the df to a csv file\n",
    "    df.to_csv(os.path.join(outputDir, f\"narrative{n}.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
